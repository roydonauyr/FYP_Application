{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation Of Vector Store Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sin Yee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Retrievers\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "    api_key=os.environ['AZURE_OPENAI_APIKEY'],\n",
    "    deployment_name=os.environ['AZURE_OPENAI_DEPLOYMENT_NAME'],\n",
    "    model_name=os.environ['AZURE_OPENAI_MODEL_NAME'],\n",
    "    api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for filename in os.listdir('C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Sin Yee'):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(f'C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Sin Yee\\\\{filename}') as f:\n",
    "            data = json.load(f)\n",
    "            for response_label, conversation in data.items():\n",
    "                doc_content = json.dumps(conversation)\n",
    "                doc_metadata = {\"label\": response_label, \"source\": filename}\n",
    "                documents.append(Document(page_content=doc_content, metadata=doc_metadata))\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "open_ai_embeddings = AzureOpenAIEmbeddings(azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'], \n",
    "                                   api_key=os.environ['AZURE_OPENAI_APIKEY'], \n",
    "                                   model=os.environ['TEXT_EMBEDDING_MODEL_NAME'],\n",
    "                                   azure_deployment=os.environ['TEXT_EMBEDDING_DEPLOYMENT_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector store\n",
    "faiss_vectorstore_open_ai_SinYee = FAISS.from_documents(documents, open_ai_embeddings)\n",
    "## Saving Vector Store\n",
    "faiss_vectorstore_open_ai_SinYee.save_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Sin Yee\\\\faiss_vectorstore_open_ai_SinYee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instruction prompt\n",
    "persona = \"\"\"You would be assisting in identifying topics from a snippet of conversation\"\"\"\n",
    "task = \"\"\"I would supply the conversation directly. Interpret the main topic of the conversation and return the main topic. Do not give multiple topics such as football/soccer. Only give one main topic.\"\"\"\n",
    "example = \"\"\"For example if the conversation is: \n",
    "            {\"Sin Yee\": \"Can't wait for the new football season to start, hoping for a great one for Arsenal!\", \"John\": \"Hey Sin Yee! Yeah, it's always exciting to see how your team will perform.\"}\n",
    "\n",
    "           football\n",
    "\n",
    "            Example 2:\n",
    "            {\"Sin Yee\": \"I'm planning to go on a trip to Japan next year\", \"John\": \"That's awesome! Japan is such a beautiful country.\"}\n",
    "\n",
    "            travel\n",
    "\n",
    "            Example 3: If no main topic can be determined such as a greeting\n",
    "            {\"Sin Yee\": \"Hey there! How are you doing?\", \"John\": \"Hey Sin Yee! I'm doing great, how about you?\"}\n",
    "\n",
    "            general\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    instruction = f\"{persona} {task} {example}\"\n",
    "    messages = [SystemMessage(content=instruction)]\n",
    "\n",
    "    query = doc.page_content\n",
    "\n",
    "    usermsg = HumanMessage(content=query)\n",
    "    messages.append(usermsg)\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    doc.metadata['topic'] = response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='{\"Xavier\": \"Me too, Sin Yee! Let's continue to inspire and motivate each other. I can't wait to see how far we'll both go in our crocheting journey.\"}' metadata={'label': 'Response 11', 'source': 'Xavier.json', 'topic': 'crocheting'}\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convert the documents list to a JSON serializable format\n",
    "documents_json = [\n",
    "    {\n",
    "        \"metadata\": doc.metadata,\n",
    "        \"page_content\": doc.page_content\n",
    "    }\n",
    "    for doc in documents\n",
    "]\n",
    "\n",
    "# Specify the file path for the JSON file\n",
    "json_file_path = 'C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Sin Yee\\\\documents.json'\n",
    "\n",
    "# Save the documents list into a JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(documents_json, json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "position = []\n",
    "count = 0\n",
    "\n",
    "for doc in documents:\n",
    "    if(len(doc.metadata['topic'].split()) > 1):\n",
    "        print(doc.metadata['topic'])\n",
    "        position.append(count)\n",
    "    count += 1\n",
    "\n",
    "print(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for doc in documents:\n",
    "    if(len(doc.metadata['topic']) == 0):\n",
    "        print(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'crochet': 1, 'art': 1, 'crafts': 1, 'crafting': 1, 'design': 1, 'gardening': 1, 'travel': 1, 'food': 1, 'fitness': 1, 'work': 1, 'healthcare': 1, 'health': 1, 'workload': 1, 'relaxation': 1, 'stress': 1, 'career': 1, 'nursing': 1, 'general': 1, 'crocheting': 1, 'knitting': 1, 'goal': 1, 'hobbies': 1, 'friendship': 1}\n"
     ]
    }
   ],
   "source": [
    "temp = {}\n",
    "\n",
    "for doc in documents:\n",
    "    if(doc.metadata['topic'] not in temp):\n",
    "        temp[doc.metadata['topic']] = 1\n",
    "\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=os.environ['HUGGING_FACE_ACCESS_TOKEN'],\n",
    "    model_name='BAAI/bge-base-en-v1.5'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x245d28a8b50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector store\n",
    "faiss_vectorstore_SinYee = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "faiss_vectorstore_SinYee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving Vector Store\n",
    "faiss_vectorstore_SinYee.save_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Sin Yee\\\\faiss_vectorstore_SinYee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lee Hang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Retrievers\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "    api_key=os.environ['AZURE_OPENAI_APIKEY'],\n",
    "    deployment_name=os.environ['AZURE_OPENAI_DEPLOYMENT_NAME'],\n",
    "    model_name=os.environ['AZURE_OPENAI_MODEL_NAME'],\n",
    "    api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for filename in os.listdir('C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Lee Hang'):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(f'C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Lee Hang\\\\{filename}') as f:\n",
    "            data = json.load(f)\n",
    "            for response_label, conversation in data.items():\n",
    "                doc_content = json.dumps(conversation)\n",
    "                doc_metadata = {\"label\": response_label, \"source\": filename}\n",
    "                documents.append(Document(page_content=doc_content, metadata=doc_metadata))\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "open_ai_embeddings = AzureOpenAIEmbeddings(azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'], \n",
    "                                   api_key=os.environ['AZURE_OPENAI_APIKEY'], \n",
    "                                   model=os.environ['TEXT_EMBEDDING_MODEL_NAME'],\n",
    "                                   azure_deployment=os.environ['TEXT_EMBEDDING_DEPLOYMENT_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector store\n",
    "faiss_vectorstore_open_ai_Lee_Hang = FAISS.from_documents(documents, open_ai_embeddings)\n",
    "## Saving Vector Store\n",
    "faiss_vectorstore_open_ai_Lee_Hang.save_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Lee Hang\\\\faiss_vectorstore_open_ai_Lee_Hang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instruction prompt\n",
    "meta_content = \"\"\"\n",
    "You would be assisting in identifying topics from a snippet of conversation. I would supply the conversation directly. \n",
    "Interpret the main topic of the conversation and return the main topic.\n",
    "\n",
    "Do not give multiple topics such as football/soccer. Only give one main topic.\n",
    "\n",
    "For example if the conversation is: \n",
    "            {\"Lee Hang\": \"Can't wait for the new football season to start, hoping for a great one for Arsenal!\", \"John\": \"Hey Lee Hang! Yeah, it's \n",
    "            always exciting to see how your team will perform.\"}\n",
    "\n",
    "            football\n",
    "\n",
    "            Example 2:\n",
    "            {\"Lee Hang\": \"I'm planning to go on a trip to Japan next year\", \"John\": \"That's awesome! Japan is such a beautiful country.\"}\n",
    "\n",
    "            travel\n",
    "\n",
    "            Example 3: If no main topic can be determined such as a greeting\n",
    "            {\"Lee Hang\": \"Hey there! How are you doing?\", \"John\": \"Hey Lee Hang! I'm doing great, how about you?\"}\n",
    "\n",
    "            general \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopic(meta_content, query):\n",
    "    # Learning instructions\n",
    "    instruction = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": meta_content,\n",
    "    }\n",
    "\n",
    "    #print(\"Query is: \" + query)\n",
    "\n",
    "    # Initialize messages\n",
    "    messages = []\n",
    "\n",
    "    # Add learn instruction to message array\n",
    "    messages.append(instruction)\n",
    "\n",
    "    user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "    }\n",
    "\n",
    "    messages.append(user_message)\n",
    "\n",
    "    openai.api_type = 'openai'\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    openai.organisation= os.environ[\"OPEN_AI_ORG\"]\n",
    "\n",
    "    raw_response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages = messages,\n",
    "    )\n",
    "    topic = raw_response.choices[0].message.content\n",
    "\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    \n",
    "    query = doc.page_content\n",
    "\n",
    "    doc.metadata['topic'] = getTopic(meta_content, query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convert the documents list to a JSON serializable format\n",
    "documents_json = [\n",
    "    {\n",
    "        \"metadata\": doc.metadata,\n",
    "        \"page_content\": doc.page_content\n",
    "    }\n",
    "    for doc in documents\n",
    "]\n",
    "\n",
    "# Specify the file path for the JSON file\n",
    "json_file_path = 'C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Lee Hang\\\\documents.json'\n",
    "\n",
    "# Save the documents list into a JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(documents_json, json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cooking techniques\n",
      "culinary arts\n",
      "cooking competition\n",
      "cooking show\n",
      "elderly care\n",
      "pet training\n",
      "pet training\n",
      "pet relations\n",
      "[6, 25, 27, 29, 55, 60, 61, 66]\n"
     ]
    }
   ],
   "source": [
    "position = []\n",
    "count = 0\n",
    "\n",
    "for doc in documents:\n",
    "    if(len(doc.metadata['topic'].split()) > 1):\n",
    "        print(doc.metadata['topic'])\n",
    "        position.append(count)\n",
    "    count += 1\n",
    "\n",
    "print(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[66].metadata['topic'] = \"pet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for doc in documents:\n",
    "    if(len(doc.metadata['topic']) == 0):\n",
    "        print(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cooking': 1, 'television': 1, 'travel': 1, 'language': 1, 'technology': 1, 'fintech': 1, 'hackathon': 1, 'business': 1, 'volunteering': 1, 'activities': 1, 'stories': 1, 'elderly': 1, 'pets': 1, 'pet': 1, 'pet_adjustment': 1}\n"
     ]
    }
   ],
   "source": [
    "temp = {}\n",
    "\n",
    "for doc in documents:\n",
    "    if(doc.metadata['topic'] not in temp):\n",
    "        temp[doc.metadata['topic']] = 1\n",
    "\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=os.environ['HUGGING_FACE_ACCESS_TOKEN'],\n",
    "    model_name='BAAI/bge-base-en-v1.5'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x16bf0d26bd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector store\n",
    "faiss_vectorstore_LeeHang = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "faiss_vectorstore_LeeHang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving Vector Store\n",
    "faiss_vectorstore_LeeHang.save_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Lee Hang\\\\faiss_vectorstore_LeeHang\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gregory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Retrievers\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "    api_key=os.environ['AZURE_OPENAI_APIKEY'],\n",
    "    deployment_name=os.environ['AZURE_OPENAI_DEPLOYMENT_NAME'],\n",
    "    model_name=os.environ['AZURE_OPENAI_MODEL_NAME'],\n",
    "    api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for filename in os.listdir('C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Gregory'):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(f'C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Gregory\\\\{filename}') as f:\n",
    "            data = json.load(f)\n",
    "            for response_label, conversation in data.items():\n",
    "                doc_content = json.dumps(conversation)\n",
    "                doc_metadata = {\"label\": response_label, \"source\": filename}\n",
    "                documents.append(Document(page_content=doc_content, metadata=doc_metadata))\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "open_ai_embeddings = AzureOpenAIEmbeddings(azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'], \n",
    "                                   api_key=os.environ['AZURE_OPENAI_APIKEY'], \n",
    "                                   model=os.environ['TEXT_EMBEDDING_MODEL_NAME'],\n",
    "                                   azure_deployment=os.environ['TEXT_EMBEDDING_DEPLOYMENT_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector store\n",
    "faiss_vectorstore_open_ai_Gregory = FAISS.from_documents(documents, open_ai_embeddings)\n",
    "## Saving Vector Store\n",
    "faiss_vectorstore_open_ai_Gregory.save_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Gregory\\\\faiss_vectorstore_open_ai_Gregory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instruction prompt\n",
    "meta_content = \"\"\"\n",
    "You would be assisting in identifying topics from a snippet of conversation. I would supply the conversation directly. \n",
    "Interpret the main topic of the conversation and return the main topic.\n",
    "\n",
    "Do not give multiple topics such as football/soccer. Only give one main topic.\n",
    "\n",
    "For example if the conversation is: \n",
    "            {\"Gregory\": \"Can't wait for the new football season to start, hoping for a great one for Arsenal!\", \"John\": \"Hey Gregory! Yeah, it's \n",
    "            always exciting to see how your team will perform.\"}\n",
    "\n",
    "            football\n",
    "\n",
    "            Example 2:\n",
    "            {\"Gregory\": \"I'm planning to go on a trip to Japan next year\", \"John\": \"That's awesome! Japan is such a beautiful country.\"}\n",
    "\n",
    "            travel\n",
    "\n",
    "            Example 3: If no main topic can be determined such as a greeting\n",
    "            {\"Gregory\": \"Hey there! How are you doing?\", \"John\": \"Hey Gregory! I'm doing great, how about you?\"}\n",
    "\n",
    "            general \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopic(meta_content, query):\n",
    "    # Learning instructions\n",
    "    instruction = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": meta_content,\n",
    "    }\n",
    "\n",
    "    #print(\"Query is: \" + query)\n",
    "\n",
    "    # Initialize messages\n",
    "    messages = []\n",
    "\n",
    "    # Add learn instruction to message array\n",
    "    messages.append(instruction)\n",
    "\n",
    "    user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "    }\n",
    "\n",
    "    messages.append(user_message)\n",
    "\n",
    "    openai.api_type = 'openai'\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    openai.organisation= os.environ[\"OPEN_AI_ORG\"]\n",
    "\n",
    "    raw_response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages = messages,\n",
    "    )\n",
    "    topic = raw_response.choices[0].message.content\n",
    "\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    \n",
    "    query = doc.page_content\n",
    "\n",
    "    doc.metadata['topic'] = getTopic(meta_content, query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convert the documents list to a JSON serializable format\n",
    "documents_json = [\n",
    "    {\n",
    "        \"metadata\": doc.metadata,\n",
    "        \"page_content\": doc.page_content\n",
    "    }\n",
    "    for doc in documents\n",
    "]\n",
    "\n",
    "# Specify the file path for the JSON file\n",
    "json_file_path = 'C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Gregory\\\\documents.json'\n",
    "\n",
    "# Save the documents list into a JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(documents_json, json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video games\n",
      "puzzle games\n",
      "video games\n",
      "television drama\n",
      "[26, 27, 28, 32]\n"
     ]
    }
   ],
   "source": [
    "position = []\n",
    "count = 0\n",
    "\n",
    "for doc in documents:\n",
    "    if(len(doc.metadata['topic'].split()) > 1):\n",
    "        print(doc.metadata['topic'])\n",
    "        position.append(count)\n",
    "    count += 1\n",
    "\n",
    "print(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for doc in documents:\n",
    "    if(len(doc.metadata['topic']) == 0):\n",
    "        print(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'travel': 1, 'food': 1, 'gaming': 1, 'video games': 1, 'puzzle games': 1, 'kdramas': 1, 'movies': 1, 'television drama': 1, 'television': 1, 'entertainment': 1, 'football': 1, 'sports': 1}\n"
     ]
    }
   ],
   "source": [
    "temp = {}\n",
    "\n",
    "for doc in documents:\n",
    "    if(doc.metadata['topic'] not in temp):\n",
    "        temp[doc.metadata['topic']] = 1\n",
    "\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=os.environ['HUGGING_FACE_ACCESS_TOKEN'],\n",
    "    model_name='BAAI/bge-base-en-v1.5'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1afff8de0d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector store\n",
    "faiss_vectorstore_Gregory = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "faiss_vectorstore_Gregory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving Vector Store\n",
    "faiss_vectorstore_Gregory.save_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Gregory\\\\faiss_vectorstore_Gregory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cheryl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Retrievers\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "    api_key=os.environ['AZURE_OPENAI_APIKEY'],\n",
    "    deployment_name=os.environ['AZURE_OPENAI_DEPLOYMENT_NAME'],\n",
    "    model_name=os.environ['AZURE_OPENAI_MODEL_NAME'],\n",
    "    api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for filename in os.listdir('C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Cheryl'):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(f'C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Cheryl\\\\{filename}') as f:\n",
    "            data = json.load(f)\n",
    "            for response_label, conversation in data.items():\n",
    "                doc_content = json.dumps(conversation)\n",
    "                doc_metadata = {\"label\": response_label, \"source\": filename}\n",
    "                documents.append(Document(page_content=doc_content, metadata=doc_metadata))\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "open_ai_embeddings = AzureOpenAIEmbeddings(azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'], \n",
    "                                   api_key=os.environ['AZURE_OPENAI_APIKEY'], \n",
    "                                   model=os.environ['TEXT_EMBEDDING_MODEL_NAME'],\n",
    "                                   azure_deployment=os.environ['TEXT_EMBEDDING_DEPLOYMENT_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector store\n",
    "faiss_vectorstore_open_ai_Cheryl = FAISS.from_documents(documents, open_ai_embeddings)\n",
    "## Saving Vector Store\n",
    "faiss_vectorstore_open_ai_Cheryl.save_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Cheryl\\\\faiss_vectorstore_open_ai_Cheryl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instruction prompt\n",
    "meta_content = \"\"\"\n",
    "You would be assisting in identifying topics from a snippet of conversation. I would supply the conversation directly. \n",
    "Interpret the main topic of the conversation and return the main topic.\n",
    "\n",
    "Do not give multiple topics such as football/soccer. Only give one main topic.\n",
    "\n",
    "For example if the conversation is: \n",
    "            {\"Cheryl\": \"Can't wait for the new football season to start, hoping for a great one for Arsenal!\", \"John\": \"Hey Cheryl! Yeah, it's \n",
    "            always exciting to see how your team will perform.\"}\n",
    "\n",
    "            football\n",
    "\n",
    "            Example 2:\n",
    "            {\"Cheryl\": \"I'm planning to go on a trip to Japan next year\", \"John\": \"That's awesome! Japan is such a beautiful country.\"}\n",
    "\n",
    "            travel\n",
    "\n",
    "            Example 3: If no main topic can be determined such as a greeting\n",
    "            {\"Cheryl\": \"Hey there! How are you doing?\", \"John\": \"Hey Cheryl! I'm doing great, how about you?\"}\n",
    "\n",
    "            general \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopic(meta_content, query):\n",
    "    # Learning instructions\n",
    "    instruction = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": meta_content,\n",
    "    }\n",
    "\n",
    "    #print(\"Query is: \" + query)\n",
    "\n",
    "    # Initialize messages\n",
    "    messages = []\n",
    "\n",
    "    # Add learn instruction to message array\n",
    "    messages.append(instruction)\n",
    "\n",
    "    user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "    }\n",
    "\n",
    "    messages.append(user_message)\n",
    "\n",
    "    openai.api_type = 'openai'\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    openai.organisation= os.environ[\"OPEN_AI_ORG\"]\n",
    "\n",
    "    raw_response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages = messages,\n",
    "    )\n",
    "    topic = raw_response.choices[0].message.content\n",
    "\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    \n",
    "    query = doc.page_content\n",
    "\n",
    "    doc.metadata['topic'] = getTopic(meta_content, query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convert the documents list to a JSON serializable format\n",
    "documents_json = [\n",
    "    {\n",
    "        \"metadata\": doc.metadata,\n",
    "        \"page_content\": doc.page_content\n",
    "    }\n",
    "    for doc in documents\n",
    "]\n",
    "\n",
    "# Specify the file path for the JSON file\n",
    "json_file_path = 'C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Cheryl\\\\documents.json'\n",
    "\n",
    "# Save the documents list into a JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(documents_json, json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outdoor activities\n",
      "Formula 1\n",
      "event planning\n",
      "marathon training\n",
      "[17, 18, 19, 46]\n"
     ]
    }
   ],
   "source": [
    "position = []\n",
    "count = 0\n",
    "\n",
    "for doc in documents:\n",
    "    if(len(doc.metadata['topic'].split()) > 1):\n",
    "        print(doc.metadata['topic'])\n",
    "        position.append(count)\n",
    "    count += 1\n",
    "\n",
    "print(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for doc in documents:\n",
    "    if(len(doc.metadata['topic']) == 0):\n",
    "        print(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cooking': 1, 'decorating': 1, 'gifts': 1, 'travel': 1, 'hiking': 1, 'outdoor activities': 1, 'Formula 1': 1, 'event planning': 1, 'sports': 1, 'shopping': 1, 'racing': 1, 'promotions': 1, 'entertainment': 1, 'memories': 1, 'advice': 1, 'photography': 1, 'marathon': 1, 'fitness': 1, 'marathon training': 1, 'nutrition': 1, 'running': 1, 'exercise': 1, 'badminton': 1, 'sports ': 1}\n"
     ]
    }
   ],
   "source": [
    "temp = {}\n",
    "\n",
    "for doc in documents:\n",
    "    if(doc.metadata['topic'] not in temp):\n",
    "        temp[doc.metadata['topic']] = 1\n",
    "\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=os.environ['HUGGING_FACE_ACCESS_TOKEN'],\n",
    "    model_name='BAAI/bge-base-en-v1.5'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1afe69fe150>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector store\n",
    "faiss_vectorstore_Cheryl = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "faiss_vectorstore_Cheryl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving Vector Store\n",
    "faiss_vectorstore_Cheryl.save_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Cheryl\\\\faiss_vectorstore_Cheryl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yu Min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Retrievers\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "    api_key=os.environ['AZURE_OPENAI_APIKEY'],\n",
    "    deployment_name=os.environ['AZURE_OPENAI_DEPLOYMENT_NAME'],\n",
    "    model_name=os.environ['AZURE_OPENAI_MODEL_NAME'],\n",
    "    api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for filename in os.listdir('C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Yu Min'):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(f'C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Yu Min\\\\{filename}') as f:\n",
    "            data = json.load(f)\n",
    "            for response_label, conversation in data.items():\n",
    "                doc_content = json.dumps(conversation)\n",
    "                doc_metadata = {\"label\": response_label, \"source\": filename}\n",
    "                documents.append(Document(page_content=doc_content, metadata=doc_metadata))\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "open_ai_embeddings = AzureOpenAIEmbeddings(azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'], \n",
    "                                   api_key=os.environ['AZURE_OPENAI_APIKEY'], \n",
    "                                   model=os.environ['TEXT_EMBEDDING_MODEL_NAME'],\n",
    "                                   azure_deployment=os.environ['TEXT_EMBEDDING_DEPLOYMENT_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector store\n",
    "faiss_vectorstore_open_ai_Yumin = FAISS.from_documents(documents, open_ai_embeddings)\n",
    "## Saving Vector Store\n",
    "faiss_vectorstore_open_ai_Yumin.save_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Yu Min\\\\faiss_vectorstore_open_ai_Yumin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instruction prompt\n",
    "meta_content = \"\"\"\n",
    "You would be assisting in identifying topics from a snippet of conversation. I would supply the conversation directly. \n",
    "Interpret the main topic of the conversation and return the main topic.\n",
    "\n",
    "Do not give multiple topics such as football/soccer. Only give one main topic.\n",
    "\n",
    "For example if the conversation is: \n",
    "            {\"Yu Min\": \"Can't wait for the new football season to start, hoping for a great one for Arsenal!\", \"John\": \"Hey Yu Min! Yeah, it's \n",
    "            always exciting to see how your team will perform.\"}\n",
    "\n",
    "            football\n",
    "\n",
    "            Example 2:\n",
    "            {\"Yu Min\": \"I'm planning to go on a trip to Japan next year\", \"John\": \"That's awesome! Japan is such a beautiful country.\"}\n",
    "\n",
    "            travel\n",
    "\n",
    "            Example 3: If no main topic can be determined such as a greeting\n",
    "            {\"Yu Min\": \"Hey there! How are you doing?\", \"John\": \"Hey Yu Min! I'm doing great, how about you?\"}\n",
    "\n",
    "            general \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopic(meta_content, query):\n",
    "    # Learning instructions\n",
    "    instruction = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": meta_content,\n",
    "    }\n",
    "\n",
    "    #print(\"Query is: \" + query)\n",
    "\n",
    "    # Initialize messages\n",
    "    messages = []\n",
    "\n",
    "    # Add learn instruction to message array\n",
    "    messages.append(instruction)\n",
    "\n",
    "    user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "    }\n",
    "\n",
    "    messages.append(user_message)\n",
    "\n",
    "    openai.api_type = 'openai'\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    openai.organisation= os.environ[\"OPEN_AI_ORG\"]\n",
    "\n",
    "    raw_response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages = messages,\n",
    "    )\n",
    "    topic = raw_response.choices[0].message.content\n",
    "\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    \n",
    "    query = doc.page_content\n",
    "\n",
    "    doc.metadata['topic'] = getTopic(meta_content, query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convert the documents list to a JSON serializable format\n",
    "documents_json = [\n",
    "    {\n",
    "        \"metadata\": doc.metadata,\n",
    "        \"page_content\": doc.page_content\n",
    "    }\n",
    "    for doc in documents\n",
    "]\n",
    "\n",
    "# Specify the file path for the JSON file\n",
    "json_file_path = 'C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Yu Min\\\\documents.json'\n",
    "\n",
    "# Save the documents list into a JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(documents_json, json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adrenaline sports\n",
      "dining out\n",
      "event planning\n",
      "event planning\n",
      "event planning\n",
      "event planning\n",
      "video games\n",
      "[11, 20, 22, 27, 31, 35, 67]\n"
     ]
    }
   ],
   "source": [
    "position = []\n",
    "count = 0\n",
    "\n",
    "for doc in documents:\n",
    "    if(len(doc.metadata['topic'].split()) > 1):\n",
    "        print(doc.metadata['topic'])\n",
    "        position.append(count)\n",
    "    count += 1\n",
    "\n",
    "print(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[20].metadata['topic'] = \"event planning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for doc in documents:\n",
    "    if(len(doc.metadata['topic']) == 0):\n",
    "        print(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adventure': 1, 'travel': 1, 'challenge': 1, 'skydiving': 1, 'cityscape': 1, 'party': 1, 'beverages': 1, 'event planning': 1, 'music': 1, 'events': 1, 'cooking': 1, 'baking': 1, 'hobbies': 1, 'relationship': 1, 'swimming': 1, 'education': 1, 'motivation': 1, 'sports': 1, 'video games': 1, 'floorball': 1}\n"
     ]
    }
   ],
   "source": [
    "temp = {}\n",
    "\n",
    "for doc in documents:\n",
    "    if(doc.metadata['topic'] not in temp):\n",
    "        temp[doc.metadata['topic']] = 1\n",
    "\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=os.environ['HUGGING_FACE_ACCESS_TOKEN'],\n",
    "    model_name='BAAI/bge-base-en-v1.5'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1afff8ea590>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector store\n",
    "faiss_vectorstore_Yumin = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "faiss_vectorstore_Yumin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving Vector Store\n",
    "faiss_vectorstore_Yumin.save_local(\"C:\\\\Roydon\\\\Github\\\\FYP_Application\\\\MuteCompanion\\\\MuteApp\\\\assets\\\\mockdata\\\\Yu Min\\\\faiss_vectorstore_Yumin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
